Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all', batch_size=8, cuda=True, data_path='data', decay=0, epoch=20, freeze_bert=False, gradient_clip=-1, language='ted_talk_with_utt', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='bert-base-uncased', save_path='out/fullTedTalk_newUTT_triangleHalfTo1_weightedLoss_fractionLog_seed1\r', seed=1, sequence_length=256, sliding_window=True, stride_size=0.5, sub_style='unk', trained_model_path=False)
epoch: 0, Train loss: 0.6770981195165479, Train accuracy: 0.788201630145638
epoch: 0, Val loss: 0.6622422480117812, Val accuracy: 0.8380284636672823
val_Precision: [0.98884793 0.51725218 0.63027397 0.4017455  0.54249121]
val_Recall: [0.85061348 0.83923081 0.71426231 0.64687217 0.7959648 ]
val_F1: [0.91453659 0.64002862 0.66964491 0.49565821 0.6452269 ]
epoch: 1, Train loss: 0.5250287769585305, Train accuracy: 0.8419594552137292
epoch: 1, Val loss: 0.622177952378741, Val accuracy: 0.8439698507480529
val_Precision: [0.99036916 0.52365554 0.65649726 0.46341463 0.55428351]
val_Recall: [0.85472406 0.85237636 0.7227547  0.68041704 0.8080254 ]
val_F1: [0.91756052 0.64875183 0.68803452 0.5513315  0.65752364]
epoch: 2, Train loss: 0.49109264811567793, Train accuracy: 0.8511732835010085
epoch: 2, Val loss: 0.6134440230681505, Val accuracy: 0.853342179664198
val_Precision: [0.99024929 0.55594956 0.61699791 0.4464487  0.57120729]
val_Recall: [0.86619642 0.81907603 0.7977117  0.7180417  0.81037869]
val_F1: [0.92407807 0.6623367  0.69581269 0.55057351 0.67009107]
epoch: 3, Train loss: 0.468660515990185, Train accuracy: 0.8573968468812168
epoch: 3, Val loss: 0.5931045678909427, Val accuracy: 0.8566954172419771
val_Precision: [0.99047701 0.55620783 0.64245746 0.51529735 0.57864069]
val_Recall: [0.86880565 0.84308719 0.7681385  0.67951043 0.81621865]
val_F1: [0.92566025 0.67023993 0.69969903 0.58611926 0.67719706]
epoch: 4, Train loss: 0.45283625856429877, Train accuracy: 0.8608382428243277
epoch: 4, Val loss: 0.5829398551235488, Val accuracy: 0.862586993901212
val_Precision: [0.98988377 0.5765628  0.62166395 0.51725316 0.58902399]
val_Recall: [0.87765065 0.81554536 0.81289424 0.68631006 0.81223882]
val_F1: [0.93039478 0.67554107 0.70453335 0.58990844 0.68285285]
epoch: 5, Train loss: 0.438147997676406, Train accuracy: 0.8647612773230602
epoch: 5, Val loss: 0.5819413365382382, Val accuracy: 0.8503435922877528
val_Precision: [0.99170224 0.54423801 0.62514114 0.49829139 0.56653863]
val_Recall: [0.86003831 0.82127782 0.81641681 0.72710789 0.81794035]
val_F1: [0.92118944 0.65465459 0.7080891  0.59133641 0.669414  ]
epoch: 6, Train loss: 0.4253794345918455, Train accuracy: 0.8678316429961956
epoch: 6, Val loss: 0.5887870300515587, Val accuracy: 0.8610608025853601
val_Precision: [0.99080651 0.56681196 0.64517722 0.50310366 0.58717831]
val_Recall: [0.87346241 0.83863151 0.78485022 0.73481414 0.81961015]
val_F1: [0.92844142 0.67643613 0.70819268 0.5972734  0.68419285]
epoch: 7, Train loss: 0.41416881711239817, Train accuracy: 0.870590130353117
epoch: 7, Val loss: 0.6093487606389069, Val accuracy: 0.862826083924583
val_Precision: [0.99062136 0.57746855 0.62199306 0.53243697 0.59016414]
val_Recall: [0.87629168 0.81640523 0.82679337 0.7180417  0.81781923]
val_F1: [0.92995575 0.67645773 0.70991794 0.61146497 0.68558705]
epoch: 8, Train loss: 0.4027702965769237, Train accuracy: 0.8727098104660813
epoch: 8, Val loss: 0.5945655227588328, Val accuracy: 0.8646013273481131
val_Precision: [0.99076271 0.57746352 0.63949208 0.52390308 0.59427187]
val_Recall: [0.87761182 0.83310751 0.80175309 0.72529465 0.82111556]
val_F1: [0.93076099 0.68211977 0.7114886  0.60836502 0.68951563]
epoch: 9, Train loss: 0.39315669467232417, Train accuracy: 0.8746769274258175
epoch: 9, Val loss: 0.6105834950670007, Val accuracy: 0.8696819903447479
val_Precision: [0.98997357 0.59103928 0.64136527 0.50561798 0.60398553]
val_Recall: [0.88533599 0.82805253 0.79995085 0.73436083 0.81736068]
val_F1: [0.93473552 0.68975322 0.71193361 0.59889094 0.69465697]
epoch: 10, Train loss: 0.38196827665449634, Train accuracy: 0.877035733005425
epoch: 10, Val loss: 0.617389142191469, Val accuracy: 0.8689268643542677
val_Precision: [0.99024165 0.58218891 0.6611081  0.56055493 0.60309649]
val_Recall: [0.88337389 0.85111262 0.76538052 0.67769719 0.82063971]
val_F1: [0.93375999 0.69142231 0.70943329 0.61358506 0.69524808]
epoch: 11, Train loss: 0.37323882592931673, Train accuracy: 0.878556824791526
epoch: 11, Val loss: 0.6318691774238037, Val accuracy: 0.8658645196382568
val_Precision: [0.99053738 0.58713557 0.62104054 0.50405743 0.59588022]
val_Recall: [0.88036343 0.81545417 0.82662953 0.73209429 0.81740394]
val_F1: [0.93220643 0.68271161 0.70923681 0.59704251 0.68928083]
epoch: 12, Train loss: 0.36398907655337476, Train accuracy: 0.8801970782462044
epoch: 12, Val loss: 0.6365992199143515, Val accuracy: 0.8631568251235796
val_Precision: [0.9908244  0.57518899 0.62978033 0.55098325 0.59093462]
val_Recall: [0.87629944 0.82473031 0.81573414 0.68585675 0.81922947]
val_F1: [0.93004958 0.67771878 0.7107965  0.61106624 0.68660245]
epoch: 13, Train loss: 0.3552774087653834, Train accuracy: 0.8817998992689475
epoch: 13, Val loss: 0.6571367554212852, Val accuracy: 0.8711862650751241
val_Precision: [0.98979018 0.5992346  0.62770844 0.52965375 0.60666521]
val_Recall: [0.88784169 0.81803377 0.8171814  0.70036265 0.81551785]
val_F1: [0.93604822 0.69174498 0.71002183 0.60316221 0.69575615]
epoch: 14, Train loss: 0.3460318477487452, Train accuracy: 0.8833324708102277
epoch: 14, Val loss: 0.6674725694647559, Val accuracy: 0.8643721994090492
val_Precision: [0.99074028 0.57279397 0.65254857 0.527897   0.59378129]
val_Recall: [0.87740474 0.84324352 0.77958002 0.72484134 0.82081275]
val_F1: [0.93063462 0.68219211 0.71043038 0.61088825 0.68907862]
epoch: 15, Train loss: 0.3370434735805201, Train accuracy: 0.8853705658300313
epoch: 15, Val loss: 0.6956137439342405, Val accuracy: 0.869771649103512
val_Precision: [0.98996283 0.59372939 0.62825294 0.56441006 0.60373396]
val_Recall: [0.88591064 0.82106936 0.81415035 0.66137806 0.81582932]
val_F1: [0.93505092 0.68913407 0.70922239 0.60905865 0.69393718]
epoch: 16, Train loss: 0.3282108852509, Train accuracy: 0.8865056848033962
epoch: 16, Val loss: 0.693072439960546, Val accuracy: 0.8680282843497648
val_Precision: [0.99022468 0.59084658 0.62604857 0.53645117 0.60048169]
val_Recall: [0.88313574 0.82280213 0.81314    0.70716228 0.81753372]
val_F1: [0.93361939 0.68779439 0.70743354 0.61008995 0.6923959 ]
epoch: 17, Train loss: 0.31975019346667605, Train accuracy: 0.8878815001754278
epoch: 17, Val loss: 0.7278644351191373, Val accuracy: 0.8691759164619458
val_Precision: [0.9900185  0.58877936 0.64391029 0.49661538 0.60262896]
val_Recall: [0.88499689 0.83266455 0.78708937 0.73164098 0.81629651]
val_F1: [0.93456651 0.68979957 0.70833692 0.59164223 0.69337527]
epoch: 18, Train loss: 0.31045261150798864, Train accuracy: 0.8896941305535465
epoch: 18, Val loss: 0.7489387848093101, Val accuracy: 0.8682853061248886
val_Precision: [0.99004838 0.58968304 0.6269895  0.57199056 0.60062829]
val_Recall: [0.88407538 0.82314086 0.80893476 0.65911151 0.8155092 ]
val_F1: [0.93406574 0.68712344 0.70643504 0.61246841 0.69176602]
Precision: [0.98979018 0.5992346  0.62770844 0.52965375 0.60666521]
Recall: [0.88784169 0.81803377 0.8171814  0.70036265 0.81551785]
F1 score: [0.93604822 0.69174498 0.71002183 0.60316221 0.69575615]
Accuracy:0.8711862650751241
Confusion Matrix[[342991  35891   7059    379]
 [  3236  62789  10294    437]
 [   268   5871  29926    556]
 [    34    231    396   1545]]
59.92346013628295 81.80337693470217 69.17449790126585 62.77084425799685 81.71813986510472 71.00218278447376 52.965375385670214 70.0362647325476 60.31622096427874 60.66652078211284 81.55178529714577 69.57561531903586

Precision: [0.99184923 0.59993489 0.63713822 0.60093518 0.61162836]
Recall: [0.88340877 0.84014706 0.8331394  0.74331871 0.83553579]
F1 score: [0.93449361 0.70000674 0.72207445 0.66458631 0.70626043]
Accuracy:0.8723993935161483
Confusion Matrix[[620486  65649  15374    868]
 [  4557 114260  16435    748]
 [   475  10138  57280    859]
 [    67    407    813   3727]]
59.99348924149663 84.01470588235294 70.0006739081157 63.71382171698071 83.31393995811031 72.20744513217441 60.09351821992905 74.33187076186677 66.4586305278174 61.162836144864215 83.55357874965438 70.62604266567809

